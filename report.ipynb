{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c31469b",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network\n",
    "\n",
    "## Goal :\n",
    "in this project, our goal is to fill-in the gaps of a detaset with the help of predicting our datasets using skit-learn library.\n",
    "\n",
    "## Description :\n",
    "in this project, first we want to fill-in the empty cells using different metods such as fill them with mean number of other existing numbers in that column and then discuss about them. then we are going to find a function in our skit-learn library, to find the best model for our dataset, wich can estimate the target column by considering one of the features in .csv file, . also, we need to analyze wich of the features in the file, is the best feature to be used as a measure, in order to predict the output, wich is the movie genres prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b8785db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a77c0e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 /10000 image prossesd!\n",
      "2000 /10000 image prossesd!\n",
      "3000 /10000 image prossesd!\n",
      "4000 /10000 image prossesd!\n",
      "5000 /10000 image prossesd!\n",
      "6000 /10000 image prossesd!\n",
      "7000 /10000 image prossesd!\n",
      "8000 /10000 image prossesd!\n",
      "9000 /10000 image prossesd!\n",
      "10000 /10000 image prossesd!\n"
     ]
    }
   ],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "i = 0\n",
    "\n",
    "labels = pd.DataFrame(pd.read_csv(\"labels.csv\"))\n",
    "\n",
    "list_dir=[int(file.split(\".\")[0]) for file in os.listdir(\"data\")]\n",
    "list_dir.sort()\n",
    "for filename in list_dir:\n",
    "    img = cv2.imread(os.path.join(\"data\",str(filename)+\".png\"))\n",
    "    img = img.flatten()\n",
    "    all_images.append(img)\n",
    "    i += 1\n",
    "    if i%1000 == 0:\n",
    "        print(i,\"/10000 image prossesd!\")   \n",
    "\n",
    "        \n",
    "cifar = labels.join(pd.DataFrame(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "06f4123a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>3062</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>horse</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>-124</td>\n",
       "      <td>100</td>\n",
       "      <td>-112</td>\n",
       "      <td>106</td>\n",
       "      <td>99</td>\n",
       "      <td>-114</td>\n",
       "      <td>104</td>\n",
       "      <td>96</td>\n",
       "      <td>-116</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>cat</td>\n",
       "      <td>116</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>91</td>\n",
       "      <td>101</td>\n",
       "      <td>110</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>-116</td>\n",
       "      <td>82</td>\n",
       "      <td>117</td>\n",
       "      <td>-113</td>\n",
       "      <td>84</td>\n",
       "      <td>116</td>\n",
       "      <td>-113</td>\n",
       "      <td>86</td>\n",
       "      <td>116</td>\n",
       "      <td>-112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>horse</td>\n",
       "      <td>-104</td>\n",
       "      <td>-107</td>\n",
       "      <td>-114</td>\n",
       "      <td>-89</td>\n",
       "      <td>-84</td>\n",
       "      <td>-84</td>\n",
       "      <td>-102</td>\n",
       "      <td>-88</td>\n",
       "      <td>...</td>\n",
       "      <td>-91</td>\n",
       "      <td>105</td>\n",
       "      <td>124</td>\n",
       "      <td>-98</td>\n",
       "      <td>106</td>\n",
       "      <td>125</td>\n",
       "      <td>-98</td>\n",
       "      <td>111</td>\n",
       "      <td>125</td>\n",
       "      <td>-93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>horse</td>\n",
       "      <td>-12</td>\n",
       "      <td>-41</td>\n",
       "      <td>-92</td>\n",
       "      <td>-16</td>\n",
       "      <td>-44</td>\n",
       "      <td>-94</td>\n",
       "      <td>-16</td>\n",
       "      <td>-44</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>108</td>\n",
       "      <td>-104</td>\n",
       "      <td>124</td>\n",
       "      <td>107</td>\n",
       "      <td>-102</td>\n",
       "      <td>124</td>\n",
       "      <td>100</td>\n",
       "      <td>-102</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>cat</td>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>110</td>\n",
       "      <td>118</td>\n",
       "      <td>-121</td>\n",
       "      <td>-114</td>\n",
       "      <td>120</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>49979</td>\n",
       "      <td>horse</td>\n",
       "      <td>-106</td>\n",
       "      <td>-93</td>\n",
       "      <td>-92</td>\n",
       "      <td>56</td>\n",
       "      <td>82</td>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>-23</td>\n",
       "      <td>-22</td>\n",
       "      <td>-16</td>\n",
       "      <td>-27</td>\n",
       "      <td>-31</td>\n",
       "      <td>-27</td>\n",
       "      <td>-33</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>49980</td>\n",
       "      <td>cat</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>49983</td>\n",
       "      <td>cat</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>56</td>\n",
       "      <td>82</td>\n",
       "      <td>45</td>\n",
       "      <td>59</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>49984</td>\n",
       "      <td>cat</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-44</td>\n",
       "      <td>-40</td>\n",
       "      <td>-8</td>\n",
       "      <td>-34</td>\n",
       "      <td>-31</td>\n",
       "      <td>-4</td>\n",
       "      <td>-51</td>\n",
       "      <td>-48</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>49987</td>\n",
       "      <td>horse</td>\n",
       "      <td>-55</td>\n",
       "      <td>-105</td>\n",
       "      <td>97</td>\n",
       "      <td>-55</td>\n",
       "      <td>-104</td>\n",
       "      <td>98</td>\n",
       "      <td>-55</td>\n",
       "      <td>-103</td>\n",
       "      <td>...</td>\n",
       "      <td>-61</td>\n",
       "      <td>-86</td>\n",
       "      <td>-70</td>\n",
       "      <td>-51</td>\n",
       "      <td>-93</td>\n",
       "      <td>-77</td>\n",
       "      <td>-60</td>\n",
       "      <td>-93</td>\n",
       "      <td>-78</td>\n",
       "      <td>-61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  label    0    1    2    3    4    5    6    7  ...  3062  3063  \\\n",
       "0         8  horse   39   35   28   44   34   30   47   44  ...  -124   100   \n",
       "1        10    cat  116  125  125   91  101  110   83   90  ...  -116    82   \n",
       "2        12  horse -104 -107 -114  -89  -84  -84 -102  -88  ...   -91   105   \n",
       "3        13  horse  -12  -41  -92  -16  -44  -94  -16  -44  ...   122   108   \n",
       "4        18    cat   97  104  110  118 -121 -114  120 -110  ...    52    60   \n",
       "...     ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "9995  49979  horse -106  -93  -92   56   82   94   77  102  ...   -23   -22   \n",
       "9996  49980    cat    4    4    4    4    4    4    5    5  ...     7    11   \n",
       "9997  49983    cat   41   41   41   37   39   39   36   39  ...    81    44   \n",
       "9998  49984    cat   21   29   41   20   28   43   16   26  ...   -17   -44   \n",
       "9999  49987  horse  -55 -105   97  -55 -104   98  -55 -103  ...   -61   -86   \n",
       "\n",
       "      3064  3065  3066  3067  3068  3069  3070  3071  \n",
       "0     -112   106    99  -114   104    96  -116   101  \n",
       "1      117  -113    84   116  -113    86   116  -112  \n",
       "2      124   -98   106   125   -98   111   125   -93  \n",
       "3     -104   124   107  -102   124   100  -102   120  \n",
       "4       48    45    60    46    47    62    48    51  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "9995   -16   -27   -31   -27   -33    -2    -2    -2  \n",
       "9996    13    12    11    11    11     3     3     3  \n",
       "9997    56    80    44    56    82    45    59    85  \n",
       "9998   -40    -8   -34   -31    -4   -51   -48   -14  \n",
       "9999   -70   -51   -93   -77   -60   -93   -78   -61  \n",
       "\n",
       "[10000 rows x 3074 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1349b1da",
   "metadata": {},
   "source": [
    "as we can seewe have flaten each of our images and now the numbers are between -128 to 127 wich when we call the train-test fynction they woud change to 0-255 and then for normalizaing we only have to devide it in 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15fc33f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5583\n",
      "[ 67  60  49 ...  95 105 133]\n",
      "horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_images, labels, test_size=0.2) \n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "rand_num = np.random.randint(len(X_train))\n",
    "print(rand_num)\n",
    "plt.imshow(X_train[rand_num].reshape(32,32,3))\n",
    "print(X_train[rand_num])\n",
    "print(y_train[rand_num][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6fd53b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse\n",
      "[105 156 147 ... 226 234 240]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(32,32,3))\n",
    "print(y_train[0][1])\n",
    "print(X_train[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cd0503b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "[102 101 113 ...  26  48  82]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5].reshape(32,32,3))\n",
    "print(y_train[5][1])\n",
    "print(X_train[5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f1ca9",
   "metadata": {},
   "source": [
    "### part 1-3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7cedde8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 4024\n",
      "horse: 3976\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"cat:\",np.count_nonzero(y_train == \"cat\"))\n",
    "print(\"horse:\",np.count_nonzero(y_train == \"horse\"))\n",
    "plt.bar([\"cat\",\"hourse\"],[np.count_nonzero(y_train == \"cat\"), np.count_nonzero(y_train == \"horse\")])\n",
    "plt.title(\"train\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f71a3470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: 976\n",
      "horse: 1024\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"cat:\",np.count_nonzero(y_test == \"cat\"))\n",
    "print(\"horse:\",np.count_nonzero(y_test == \"horse\"))\n",
    "plt.bar([\"cat\",\"hourse\"],[np.count_nonzero(y_test == \"cat\"), np.count_nonzero(y_test == \"horse\")])\n",
    "plt.title(\"test\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194bdc0b",
   "metadata": {},
   "source": [
    "### part 1-4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61cd7e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105 156 147 ... 226 234 240]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.41176471, 0.61176471, 0.57647059, ..., 0.88627451, 0.91764706,\n",
       "       0.94117647])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = X_train[i]/255\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = X_test[i]/255\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bf405c",
   "metadata": {},
   "source": [
    "The reason for normalizing the images is to avoid the possibility of exploding gradients because of the high range of the pixels [0, 255], and improve the convergence speed. Therefore, you either standardize the each image, so that the range is [-1, 1] or you just divide the with the maximum pixel value as you are doing, so that the range of the pixels is in the [0, 1] range.\n",
    "\n",
    "Another reason why you might want to normalize the image data is if you are using transfer learning. For example, if you are using a pre-trained model that has been trained with images with pixels in the [0, 1] range, you should make sure that the inputs you are providing the model are in the same range. Otherwise, your results will be messed up.\n",
    "\n",
    "### part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c19b54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    \n",
    "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
    "\n",
    "        assert len(data)==len(labels)\n",
    "        self.__n_classes = n_classes\n",
    "        self.__batch_size = batch_size\n",
    "        self.__shuffle = shuffle\n",
    "        self.__data = data\n",
    "        self.__onehot_labels = self.__onehot(labels, self.__n_classes)\n",
    "    \n",
    "    def __onehot(self, labels, n_classes):\n",
    "\n",
    "        onehot_vectors = []\n",
    "        onehot = dict()\n",
    "        i = 0\n",
    "        for label in labels:\n",
    "            if label not in onehot:\n",
    "                onehot[label] = np.zeros(n_classes)\n",
    "                onehot[label][i] = 1\n",
    "                i += 1\n",
    "            onehot_vectors.append(onehot[label])   \n",
    "            \n",
    "        return onehot_vectors\n",
    "    \n",
    "    \n",
    "    def __shuffle_dataset(self):\n",
    "\n",
    "        shuffled_data = []\n",
    "        shuffled_labels = []\n",
    "        if self.__shuffle:\n",
    "            shuffled_indx = random.sample(range(len(data)), len(data))\n",
    "            for i in shuffled_indx:\n",
    "                shuffled_data.append(self.__data[i])\n",
    "                shuffled_labels.append(self.__onehot_labels[i])\n",
    "\n",
    "            self.__data = shuffled_data\n",
    "            self.__onehot_labels = shuffled_labels\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \n",
    "        if self.__shuffle:\n",
    "            self.__shuffle_dataset()\n",
    "            \n",
    "        if self.__batch_size==None:\n",
    "            yield (np.matrix(self.__data), np.matrix(self.__onehot_labels))\n",
    "            return\n",
    "            \n",
    "        for idx in range(0, len(self.__data), self.__batch_size):\n",
    "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
    "                   np.matrix(self.__onehot_labels[idx:idx+self.__batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d49e53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identical:\n",
    "\n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        identical_value = np.matrix(matrix, dtype=float)\n",
    "        return identical_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "\n",
    "        temp = np.matrix(matrix, dtype=float)\n",
    "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
    "        return identical_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        return self.__val(matrix)\n",
    "    \n",
    "\n",
    "class Relu:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "\n",
    "        relu_value = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(relu_value)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if matrix[i,j] < 0 :\n",
    "                    relu_value[i,j] = 0\n",
    "        return relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        relu_derivative = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(relu_derivative)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if matrix[i,j] < 0 :\n",
    "                    relu_derivative[i,j] = 0\n",
    "                else:\n",
    "                    relu_derivative[i,j] = 1\n",
    "        return relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        \n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class LeakyRelu:\n",
    "    \n",
    "    def __init__(self, negative_slope=0.01):\n",
    "        \n",
    "        self.negative_slope = 0.01\n",
    "    \n",
    "    def __val(self, matrix):\n",
    "        leacky_relu_value = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(leacky_relu_value)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if matrix[i,j] < 0 :\n",
    "                    leacky_relu_value[i,j] = self.negative_slope*matrix[i,j]\n",
    "        return leacky_relu_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        \n",
    "        leacky_relu_derivative = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(leacky_relu_derivative)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if matrix[i,j] < 0 :\n",
    "                    leacky_relu_derivative[i,j] = self.negative_slope\n",
    "                else:\n",
    "                    leacky_relu_derivative[i,j] = 1\n",
    "        return leacky_relu_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        \n",
    "        return self.__val(matrix)\n",
    "\n",
    "    \n",
    "class Sigmoid:\n",
    "\n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        \n",
    "        sigmoid_value = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(sigmoid_value)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                sigmoid_value[i,j] = 1/(1+np.exp(-1*matrix[i,j]))\n",
    "        return sigmoid_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        \n",
    "        sigmoid_derivative = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(sigmoid_derivative)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                if matrix[i,j] < 0 :\n",
    "                    leacky_relu_derivative[i,j] = (1/(1+np.exp(-1*matrix[i,j])))*(1-(1/(1+np.exp(-1*matrix[i,j]))))              \n",
    "        return sigmoid_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "\n",
    "        return self.__val(matrix)\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "        \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        softmax_value = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(softmax_value)\n",
    "        for j in range(col):\n",
    "            denominator = sum(np.exp(matrix))[0,j]\n",
    "            for i in range(row):\n",
    "                softmax_value[i,j] = np.exp(matrix[i,j])/denominator\n",
    "        return softmax_value\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "        \n",
    "        return self.__val(matrix)\n",
    "    \n",
    "class Tanh:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, matrix):\n",
    "        tanh_value = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(tanh_value)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                tanh_value[i,j] = np.tanh(matrix[i,j])\n",
    "        return tanh_value\n",
    "\n",
    "    def derivative(self, matrix):\n",
    "        tanh_derivative = np.matrix.copy(matrix)\n",
    "        row, col = np.shape(tanh_derivative)\n",
    "        for i in range(row):\n",
    "            for j in range(col):\n",
    "                tanh_derivative[i,j] = 1/((np.cosh(matrix[i,j]))**2)\n",
    "        return tanh_derivative\n",
    "    \n",
    "    def __call__(self, matrix):\n",
    "\n",
    "        return self.__val(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "618359cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    \n",
    "    def __init__(self): pass\n",
    "\n",
    "    def __val(self, true_val, expected_val):\n",
    "\n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        cross_entropy_value = 0\n",
    "        for i in range(len(true_val)):\n",
    "            cross_entropy_value += expected_val[i]*np.log(true_val[i])\n",
    "            \n",
    "        return cross_entropy_value\n",
    "    \n",
    "    def derivative(self, true_val, expected_val):\n",
    "        \n",
    "        assert np.shape(true_val)==np.shape(expected_val)\n",
    "        cross_entropy_derivative = []\n",
    "        for i in range(len(true_val)):\n",
    "            cross_entropy_derivative[i] = expected_val[i]/true_val[i]\n",
    "        return cross_entropy_derivative\n",
    "    \n",
    "    def __call__(self, true_val, expected_val):\n",
    "\n",
    "        return self.__val(true_val, expected_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7d9568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "\n",
    "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, weights = 0, 0.05, 0., 1.\n",
    "  \n",
    "    def __init__(self, input_size, output_size, activation=Identical(), initial_weight='uniform', \n",
    "                 **initializing_parameters):\n",
    "        \n",
    "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
    "        \n",
    "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
    "        \n",
    "        assert initial_weight in self.__weight_initializer_dict, 'Undefined weight initialization function!'\n",
    "\n",
    "\n",
    "        self.__n_neurons = output_size\n",
    "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
    "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
    "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
    "        self.__activation = activation\n",
    "        \n",
    "        self.__last_input = None\n",
    "        self.__last_activation_input = None\n",
    "        self.__last_activation_output = None\n",
    "        self.__last_activation_derivative = None\n",
    "        \n",
    "    def forward(self, layer_input):\n",
    "        \n",
    "        assert np.ndim(layer_input)==2\n",
    "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.__last_input = layer_input\n",
    "        self.__last_activation_input = activation(self.__last_input)\n",
    "        self.__last_activation_derivative = activation.derivative(self.__last_activation_input)\n",
    "        \n",
    "        \n",
    "        for k in range(len(self.__n_neurons)):\n",
    "            self.__last_activation_output[k] = self.__bias\n",
    "            for i in range(len(input_size)):\n",
    "                self.__last_activation_output[k] += self.__last_input[i,0]*self.__weight[i,k]\n",
    "        \n",
    "        self.__last_activation_output = activation(self.__last_activation_output)   \n",
    "        return self.__last_activation_output\n",
    "    \n",
    "    def update_weights(self, backprop_tensor, lr):\n",
    "\n",
    "        assert np.ndim(backprop_tensor)==2\n",
    "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
    "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
    "\n",
    "        tensor_out = np.matmul(backprop_tensor, np.matrix.transpose(self.__weight))       \n",
    "        self.__weight = self.__weight - lr*np.matmul(np.matrix.transpose(self.__last_input),backprop_tensor)\n",
    "        backprop_tensor = tensor_out\n",
    "        \n",
    "        return backprop_tensor\n",
    "    \n",
    "\n",
    "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
    "\n",
    "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
    "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
    "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
    "        \n",
    "        weights = np.random.uniform(low, high, size=(dim1, dim2))\n",
    "        \n",
    "        return weights\n",
    "\n",
    "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
    "\n",
    "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
    "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
    "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
    "        \n",
    "        weights = np.random.normal(mean, np.sqrt(var), size=(dim1, dim2))\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    @property\n",
    "    def n_neurons(self): return self.__n_neurons\n",
    "    \n",
    "    @property\n",
    "    def weight(self): return self.__weight\n",
    "    \n",
    "    @property\n",
    "    def bias(self): return self.__bias\n",
    "    \n",
    "    @property\n",
    "    def activation(self): return self.__activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a3950667",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN:\n",
    "\n",
    "    def __init__(self, input_shape):\n",
    "        \n",
    "        self.__input_shape = input_shape\n",
    "        self.__output_shape = None\n",
    "        \n",
    "        self.__layers_list = []\n",
    "        \n",
    "        self.__lr = None\n",
    "        self.__loss = None\n",
    "\n",
    "        \n",
    "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
    "         \n",
    "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
    "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
    "        \n",
    "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
    "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
    "        self.__layers_list.append(new_layer)\n",
    "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
    "      \n",
    "    \n",
    "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
    "        \n",
    "        assert self.__layers_list, \"Uncomplete model!\"\n",
    "        self.__loss = loss\n",
    "        self.__lr = lr\n",
    "    \n",
    "    \n",
    "    def forward(self, network_input):\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "                \n",
    "        for i in range(len(self.__layers_list)):\n",
    "                network_input = self.__layers_list[i].forward(network_input)\n",
    "        \n",
    "        network_output = network_input\n",
    "        return network_output\n",
    "    \n",
    "    \n",
    "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
    "        \n",
    "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
    "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
    "\n",
    "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
    "        \n",
    "        for epoch in range(1, epochs+1):\n",
    "            \n",
    "            if print_results: \n",
    "                print('Epoch {}:'.format(epoch)) \n",
    "                \n",
    "            average_accuracy, average_loss = self.__train(trainloader)\n",
    "            log['train_accuracy'].append(average_accuracy)\n",
    "            log['train_loss'].append(average_loss)\n",
    "            if print_results:\n",
    "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "            \n",
    "            if type(testloader) != type(None):\n",
    "                average_accuracy, average_loss = self.__test(testloader)\n",
    "                log['test_accuracy'].append(average_accuracy)\n",
    "                log['test_loss'].append(average_loss)\n",
    "                if print_results:\n",
    "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
    "                    \n",
    "        return log\n",
    "  \n",
    "    \n",
    "    def __train(self, trainloader):\n",
    "\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_train, y_train in trainloader:\n",
    "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "    \n",
    "    \n",
    "    def __test(self, testloader):\n",
    "\n",
    "        bach_accuracies, batch_losses = [], []\n",
    "        for x_test, y_test in testloader:\n",
    "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
    "            bach_accuracies.append(batch_accuracy)\n",
    "            batch_losses.append(batch_loss)\n",
    "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
    "   \n",
    "    def __train_on_batch(self, x_batch, y_batch):\n",
    "        \n",
    "        lossdev = 1\n",
    "        while lossdev != 0:\n",
    "            network_output = self.forward(self, network_input)\n",
    "            lossdev = self.__loss.__val(network_output, y_batch)\n",
    "            self.__update_weights(lossdev,y_batch)\n",
    "            \n",
    "        batch_accuracy = self.__compute_accuracy()\n",
    "        batch_average_loss = lossdev\n",
    "        \n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "        \n",
    "        \n",
    "    def __test_on_batch(self, x_batch, y_batch):\n",
    "        \n",
    "        lossdev = 1\n",
    "        while lossdev != 0 :\n",
    "            network_output = self.forward(self, network_input)\n",
    "            lossdev = self.__loss.__val(network_output, y_batch)\n",
    "            self.__update_weights(lossdev,y_batch)\n",
    "            \n",
    "        batch_accuracy = self.__compute_accuracy()\n",
    "        batch_average_loss = lossdev\n",
    "        return (batch_accuracy, batch_average_loss)\n",
    "            \n",
    "        \n",
    "    def __get_labels(self, outputs):\n",
    "\n",
    "        labels = []\n",
    "        for i in range(len(outputs)):\n",
    "            val, indx\n",
    "            labels.append()\n",
    "        return labels\n",
    "    \n",
    "    \n",
    "    def __compute_accuracy(self, output, expected_output):\n",
    "\n",
    "        accuracy = 0\n",
    "        labels = self.__get_labels(output)\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == expected_output[i]:\n",
    "                accuracy += 1\n",
    "        accuracy = (accuracy/len(labels))*100\n",
    "    \n",
    "    \n",
    "    def __update_weights(self, output, y_train):\n",
    "\n",
    "        for i in range(len(self.__layers_list)):\n",
    "                output = self.__layers_list[i].__update_weights(output)\n",
    "        \n",
    "        network_output = network_input\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be8af6",
   "metadata": {},
   "source": [
    "Zero initialization causes the neuron to memorize the same functions almost in each iteration\n",
    "If all the weights are initialized to zeros, the derivatives will remain same for every w in W[l]. As a result, neurons will \n",
    "learn same features in each iteration. This problem is known as network failing to break symmetry. And not only zero, \n",
    "any constant initialization will produce a poor result .\n",
    "Random initialization is generally used to break the symmetry and this process gives much better accuracy than zero \n",
    "initialization. It prevents neuron from learning the same features of its inputs. Remember, neural network is very \n",
    "sensitive and prone to overfitting as it quickly memorizes the training data. But our goal is to make each neuron learns \n",
    "different functions of its input. Now a new problem may arise if the weights initialized randomly can be very high or very \n",
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "INPUT_SHAPE = 1024 \n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 15\n",
    "\n",
    "TRAINLOADER = Dataloader(data =X_train, labels = y_train, n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = X_train, labels = y_train, n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons =20 , activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(n_neurons =20 , activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(n_neurons = 2, activation = Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc9016",
   "metadata": {},
   "source": [
    "Combining ReLU, the hyper-parameterized1 leaky variant, and variant with dynamic parametrization during learning confuses two distinct things:\n",
    "The comparison between ReLU with the leaky variant is closely related to whether there is a need, in the particular ML case at hand, to avoid saturation â€” Saturation is thee loss of signal to either zero gradient2 or the dominance of chaotic noise arising from digital rounding3.\n",
    "The comparison between training-dynamic activation (called parametric in the literature) and training-static activation must be based on whether the non-linear or non-smooth characteristics of activation have any value related to the rate of convergence4.\n",
    "The reason ReLU is never parametric is that to make it so would be redundant. In the negative domain, it is the constant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaae318",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0000001\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a885b42",
   "metadata": {},
   "source": [
    "zero. In the non-negative domain, its derivative is constant. Since the activation input vector is already attenuated with a vector-matrix product (where the matrix, cube, or hyper-cube contains the attenuation parameters) there is no useful purpose in adding a parameter to vary the constant derivative for the non-negative domain.\n",
    "\n",
    "When there is curvature in the activation, it is no longer true that all the coefficients of activation are redundant as parameters. Their values may considerably alter the training process and thus the speed and reliability of convergence.\n",
    "\n",
    "For substantially deep networks, the redundancy reemerges, and there is evidence of this, both in theory and practice in the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74caae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.1\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a905bd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "INPUT_SHAPE = 1024 \n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 15\n",
    "\n",
    "TRAINLOADER = Dataloader(data = X_train, labels =  y_train, n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "TESTLOADER = Dataloader(data = X_train), labels =  y_train, n_classes = 20, batch_size = BATCH_SIZE, shuffle = False)\n",
    "\n",
    "network = FeedForwardNN(INPUT_SHAPE)\n",
    "network.add_layer(n_neurons =20 , activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(n_neurons =20 , activation=LeakyRelu(), weight_initializer='uniform')\n",
    "network.add_layer(n_neurons = 2, activation = Identical(), weight_initializer='uniform')\n",
    "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
    "\n",
    "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13cb988",
   "metadata": {},
   "source": [
    "The learning rate controls how quickly the model is adapted to the problem. Smaller learning rates require more training epochs given the smaller changes made to the weights each update, whereas larger learning rates result in rapid changes and require fewer training epochs.\n",
    "\n",
    "A learning rate that is too large can cause the model to converge too quickly to a suboptimal solution, whereas a learning rate that is too small can cause the process to get stuck.\n",
    "\n",
    "The challenge of training deep learning neural networks involves carefully selecting the learning rate. It may be the most important hyperparameter for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5621462b",
   "metadata": {},
   "source": [
    "## Refrences:\n",
    "\n",
    "[1] https://stackoverflow.com/questions/36967920/numpy-flatten-rgb-image-array\n",
    "\n",
    "[2] https://stackoverflow.com/questions/62742125/read-images-from-from-the-folder-in-the-same-order-in-which-they-appears-and-sto\n",
    "\n",
    "[3] https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "\n",
    "[4] https://www.geeksforgeeks.org/image-classifier-using-cnn/\n",
    "\n",
    "[5] https://careerkarma.com/blog/python-add-to-dictionary/#:~:text=There%20is%20no%20add()%20%2C%20append()%20%2C%20or%20insert(),assigning%20it%20a%20particular%20value.\n",
    "\n",
    "[6] https://jamesmccaffrey.wordpress.com/2019/09/23/neural-network-back-propagation-weight-update-equation-mean-squared-error-vs-cross-entropy-error/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
